{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario Ingestion Notebook\n",
    "\n",
    "This notebook ingests scenario markdown files into ChromaDB for RAG retrieval.\n",
    "\n",
    "**Purpose:** Read all 18 scenario files from `/scenarios` and embed them using Gemini Embedding 001.\n",
    "\n",
    "**Run this once before starting the app.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import required libraries and configure paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i583134/.pyenv/versions/3.13.2/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Imports successful\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# Add parent directory to path to import backend modules\n",
    "parent_dir = Path.cwd().parent\n",
    "if str(parent_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(parent_dir))\n",
    "\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "from backend.config import get_config\n",
    "\n",
    "print(\"âœ… Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Load configuration and validate API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Configuration validated\n",
      "ğŸ“Š Embedding model: models/gemini-embedding-001\n",
      "ğŸ’¾ ChromaDB path: ./app/data/chroma_db\n",
      "ğŸ“¦ Collection name: ot_scenarios\n"
     ]
    }
   ],
   "source": [
    "# Get configuration\n",
    "config = get_config()\n",
    "\n",
    "try:\n",
    "    config.validate()\n",
    "    print(\"âœ… Configuration validated\")\n",
    "    print(f\"ğŸ“Š Embedding model: {config.embedding_model}\")\n",
    "    print(f\"ğŸ’¾ ChromaDB path: {config.chroma_db_path}\")\n",
    "    print(f\"ğŸ“¦ Collection name: {config.chroma_collection_name}\")\n",
    "except ValueError as e:\n",
    "    print(f\"âŒ Configuration error: {e}\")\n",
    "    print(\"\\nMake sure you have:\")\n",
    "    print(\"1. Created .env file in app/ directory\")\n",
    "    print(\"2. Added your GOOGLE_API_KEY to .env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Helper functions defined\n"
     ]
    }
   ],
   "source": [
    "def extract_scenario_title(content: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract scenario title from markdown heading.\n",
    "    \n",
    "    Args:\n",
    "        content: Markdown file content\n",
    "    \n",
    "    Returns:\n",
    "        Scenario title, or \"Untitled\" if not found\n",
    "    \"\"\"\n",
    "    # Look for first heading (# Scenario XX: Title)\n",
    "    match = re.search(r'^#\\s+Scenario\\s+\\d+:\\s*(.+)$', content, re.MULTILINE)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    \n",
    "    # Fallback: look for any first-level heading\n",
    "    match = re.search(r'^#\\s+(.+)$', content, re.MULTILINE)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    \n",
    "    return \"Untitled Scenario\"\n",
    "\n",
    "print(\"âœ… Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Embedding Model\n",
    "\n",
    "Create Gemini Embedding 001 model instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Initializing embedding model...\n",
      "âœ… Embedding model initialized\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ“Š Initializing embedding model...\")\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(\n",
    "    model=config.embedding_model,\n",
    "    google_api_key=config.google_api_key\n",
    ")\n",
    "\n",
    "print(\"âœ… Embedding model initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize ChromaDB\n",
    "\n",
    "Create or connect to ChromaDB vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ Initializing ChromaDB at: ./app/data/chroma_db\n",
      "âœ… ChromaDB initialized\n"
     ]
    }
   ],
   "source": [
    "print(f\"ğŸ’¾ Initializing ChromaDB at: {config.chroma_db_path}\")\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=config.chroma_collection_name,\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=config.chroma_db_path\n",
    ")\n",
    "\n",
    "print(\"âœ… ChromaDB initialized\")\n",
    "\n",
    "# Check if collection already has documents\n",
    "try:\n",
    "    existing_count = vector_store._collection.count()\n",
    "    if existing_count > 0:\n",
    "        print(f\"âš ï¸  Collection already contains {existing_count} documents\")\n",
    "        print(\"   Running this notebook will ADD more documents (duplicates possible)\")\n",
    "        print(\"   Consider deleting the chroma_db folder first if you want a clean start\")\n",
    "except:\n",
    "    print(\"ğŸ“ Collection is empty (first-time ingestion)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Scenario Files\n",
    "\n",
    "Find and read all scenario markdown files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Found 18 scenario files:\n",
      "   - scenario-1.md\n",
      "   - scenario-10.md\n",
      "   - scenario-11.md\n",
      "   - scenario-12.md\n",
      "   - scenario-13.md\n",
      "   - scenario-14.md\n",
      "   - scenario-15.md\n",
      "   - scenario-16.md\n",
      "   - scenario-17.md\n",
      "   - scenario-18.md\n",
      "   - scenario-2.md\n",
      "   - scenario-3.md\n",
      "   - scenario-4.md\n",
      "   - scenario-5.md\n",
      "   - scenario-6.md\n",
      "   - scenario-7.md\n",
      "   - scenario-8.md\n",
      "   - scenario-9.md\n"
     ]
    }
   ],
   "source": [
    "# Find scenarios directory (go up two levels from app/scripts to project root)\n",
    "scenarios_dir = Path.cwd().parent.parent / \"scenarios\"\n",
    "\n",
    "if not scenarios_dir.exists():\n",
    "    raise FileNotFoundError(f\"âŒ Scenarios directory not found: {scenarios_dir}\")\n",
    "\n",
    "scenario_files = sorted(scenarios_dir.glob(\"scenario-*.md\"))\n",
    "\n",
    "if not scenario_files:\n",
    "    raise FileNotFoundError(f\"âŒ No scenario files found in: {scenarios_dir}\")\n",
    "\n",
    "print(f\"ğŸ“ Found {len(scenario_files)} scenario files:\")\n",
    "for f in scenario_files:\n",
    "    print(f\"   - {f.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Scenarios\n",
    "\n",
    "Read each scenario file and create Document objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”„ Processing scenario files...\n",
      "\n",
      "[1/18] scenario-1.md\n",
      "  â”œâ”€ ID: scenario-1\n",
      "  â”œâ”€ Title: Refusal of Treatment by Student\n",
      "  â””â”€ Length: 6137 chars\n",
      "\n",
      "[2/18] scenario-10.md\n",
      "  â”œâ”€ ID: scenario-10\n",
      "  â”œâ”€ Title: Coping with Resistance (Spinal Cord Injury)\n",
      "  â””â”€ Length: 6187 chars\n",
      "\n",
      "[3/18] scenario-11.md\n",
      "  â”œâ”€ ID: scenario-11\n",
      "  â”œâ”€ Title: Interprofessional Conflict in Psych Ward\n",
      "  â””â”€ Length: 5975 chars\n",
      "\n",
      "[4/18] scenario-12.md\n",
      "  â”œâ”€ ID: scenario-12\n",
      "  â”œâ”€ Title: Ethical Dilemma & Involuntary Hospitalization\n",
      "  â””â”€ Length: 6781 chars\n",
      "\n",
      "[5/18] scenario-13.md\n",
      "  â”œâ”€ ID: scenario-13\n",
      "  â”œâ”€ Title: Financial Ethics & Divorce in Mental Health\n",
      "  â””â”€ Length: 5921 chars\n",
      "\n",
      "[6/18] scenario-14.md\n",
      "  â”œâ”€ ID: scenario-14\n",
      "  â”œâ”€ Title: Cultural Competence and Parental Engagement\n",
      "  â””â”€ Length: 7444 chars\n",
      "\n",
      "[7/18] scenario-15.md\n",
      "  â”œâ”€ ID: scenario-15\n",
      "  â”œâ”€ Title: Language Barrier & Cultural Competence (Russian)\n",
      "  â””â”€ Length: 5289 chars\n",
      "\n",
      "[8/18] scenario-16.md\n",
      "  â”œâ”€ ID: scenario-16\n",
      "  â”œâ”€ Title: Conflict with Customer over Equipment\n",
      "  â””â”€ Length: 3883 chars\n",
      "\n",
      "[9/18] scenario-17.md\n",
      "  â”œâ”€ ID: scenario-17\n",
      "  â”œâ”€ Title: Stroke Patient and Husband's Interference\n",
      "  â””â”€ Length: 3088 chars\n",
      "\n",
      "[10/18] scenario-18.md\n",
      "  â”œâ”€ ID: scenario-18\n",
      "  â”œâ”€ Title: Stroke Patient and Husband's Interference\n",
      "  â””â”€ Length: 3088 chars\n",
      "\n",
      "[11/18] scenario-2.md\n",
      "  â”œâ”€ ID: scenario-2\n",
      "  â”œâ”€ Title: Over-Identification and Boundaries\n",
      "  â””â”€ Length: 3893 chars\n",
      "\n",
      "[12/18] scenario-3.md\n",
      "  â”œâ”€ ID: scenario-3\n",
      "  â”œâ”€ Title: Intake Interview & Emotional Parent\n",
      "  â””â”€ Length: 6160 chars\n",
      "\n",
      "[13/18] scenario-4.md\n",
      "  â”œâ”€ ID: scenario-4\n",
      "  â”œâ”€ Title: Observation Skills & Passive vs Active\n",
      "  â””â”€ Length: 3507 chars\n",
      "\n",
      "[14/18] scenario-5.md\n",
      "  â”œâ”€ ID: scenario-5\n",
      "  â”œâ”€ Title: Gifts and Professional Boundaries\n",
      "  â””â”€ Length: 3990 chars\n",
      "\n",
      "[15/18] scenario-6.md\n",
      "  â”œâ”€ ID: scenario-6\n",
      "  â”œâ”€ Title: Parental Conflict regarding School Aide\n",
      "  â””â”€ Length: 5961 chars\n",
      "\n",
      "[16/18] scenario-7.md\n",
      "  â”œâ”€ ID: scenario-7\n",
      "  â”œâ”€ Title: Privacy and Spying Spouse\n",
      "  â””â”€ Length: 5441 chars\n",
      "\n",
      "[17/18] scenario-8.md\n",
      "  â”œâ”€ ID: scenario-8\n",
      "  â”œâ”€ Title: Adolescent ADHD and Boundary Issues\n",
      "  â””â”€ Length: 5605 chars\n",
      "\n",
      "[18/18] scenario-9.md\n",
      "  â”œâ”€ ID: scenario-9\n",
      "  â”œâ”€ Title: Autism and Engaging the Disengaged\n",
      "  â””â”€ Length: 5591 chars\n",
      "\n",
      "\n",
      "âœ… Successfully processed 18/18 scenarios\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "errors = []\n",
    "\n",
    "print(\"\\nğŸ”„ Processing scenario files...\\n\")\n",
    "\n",
    "for i, file_path in enumerate(scenario_files, 1):\n",
    "    print(f\"[{i}/{len(scenario_files)}] {file_path.name}\")\n",
    "    \n",
    "    try:\n",
    "        # Read file\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # Extract metadata\n",
    "        scenario_id = file_path.stem  # e.g., \"scenario-01\"\n",
    "        title = extract_scenario_title(content)\n",
    "        \n",
    "        print(f\"  â”œâ”€ ID: {scenario_id}\")\n",
    "        print(f\"  â”œâ”€ Title: {title}\")\n",
    "        print(f\"  â””â”€ Length: {len(content)} chars\\n\")\n",
    "        \n",
    "        # Create document\n",
    "        doc = Document(\n",
    "            page_content=content,\n",
    "            metadata={\n",
    "                \"id\": scenario_id,\n",
    "                \"title\": title,\n",
    "                \"source\": file_path.name\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        documents.append(doc)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ Error: {str(e)}\\n\")\n",
    "        errors.append((file_path.name, str(e)))\n",
    "\n",
    "print(f\"\\nâœ… Successfully processed {len(documents)}/{len(scenario_files)} scenarios\")\n",
    "\n",
    "if errors:\n",
    "    print(f\"\\nâš ï¸  Errors encountered:\")\n",
    "    for filename, error in errors:\n",
    "        print(f\"   - {filename}: {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed and Store\n",
    "\n",
    "Generate embeddings and store in ChromaDB.\n",
    "\n",
    "**Note:** This step may take a few minutes as it calls the Google AI API for each scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Embedding and storing 18 documents...\n",
      "â³ This may take a few minutes...\n",
      "\n",
      "\n",
      "âœ… Successfully ingested 18 scenarios\n",
      "ğŸ“Š ChromaDB collection 'ot_scenarios' now contains 18 documents\n"
     ]
    }
   ],
   "source": [
    "if not documents:\n",
    "    raise ValueError(\"âŒ No documents to ingest\")\n",
    "\n",
    "print(f\"ğŸ”„ Embedding and storing {len(documents)} documents...\")\n",
    "print(\"â³ This may take a few minutes...\\n\")\n",
    "\n",
    "try:\n",
    "    ids = vector_store.add_documents(documents=documents)\n",
    "    print(f\"\\nâœ… Successfully ingested {len(ids)} scenarios\")\n",
    "    \n",
    "    # Verify\n",
    "    collection = vector_store._collection\n",
    "    count = collection.count()\n",
    "    print(f\"ğŸ“Š ChromaDB collection '{config.chroma_collection_name}' now contains {count} documents\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ Ingestion failed: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification\n",
    "\n",
    "Test a sample query to verify the embeddings work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Testing retrieval with sample query...\n",
      "\n",
      "Query: '\n",
      "×× ×™ ××¨×¤××” ×‘×¢×™×¡×•×§ ××ª×—×™×œ×”, ×¡×™×™××ª×™ ××ª ×œ×™××•×“×™×™ ×œ×¤× ×™ ×›×—×¦×™ ×©× ×” ×•×”×™×•× ×× ×™ ×¤×•×’×©×ª ××ª ×”××˜×•×¤×œ ×”×¨××©×•×Ÿ ×©×œ×™. ×”××˜×•×¤×œ ×©×œ×™ ×”×•× ×‘×Ÿ 56, ×”×•× ×’×‘×¨ ×¢×¦×××™ ×¢× ××’×• ×’×‘×¨×™. ×”×•× ×¢×•×‘×“ ×‘×›×™×¨ ×‘×¢×™×¨×™×™×” ×©××›×™×¨ ××ª ×›×•×œ× ×•×›×•×œ× ××›×™×¨×™× ××•×ª×•. ×”×•× ×¨×’×™×œ ×œ×”×™×•×ª ×¢×¦×××™ ×ª××™×“ ×•×—×©×•×‘ ×œ×• × ×•×¨× ×”×›×‘×•×“ ×”×¢×¦××™ ×©×œ×•. ×”×•× ×¢×‘×¨ ×ª××•× ×ª ×“×¨×›×™× ×§×©×” ×•×‘×¢×§×‘×•×ª ×–×” ×”×•× ××ª× ×™×™×“ ×‘×›×™×¡× ×’×œ×’×œ×™×. ×”×•× × ×¤×¦×¢ ×§×©×” ×‘×¨×’×œ×™×• ×•×”×•× ×¦×¨×™×š ×œ×œ××•×“ ××—×“×© ××™×š ×œ×œ×›×ª. ×ª×™×™×¢×¥ ×œ×™ ×‘×‘×§×©×” ×¢×œ ×¨×¢×™×•× ×•×ª ×©×œ ××™×š ×œ×”×ª×—×™×œ ××ª ×”××¤×’×© ×”×¨××©×•×Ÿ ×©×œ× ×•.\n",
      "'\n",
      "\n",
      "Top 2 matches:\n",
      "\n",
      "1. Refusal of Treatment by Student\n",
      "   ID: scenario-1\n",
      "   Score: 0.4451\n",
      "   Preview: # Scenario 01: Refusal of Treatment by Student\n",
      "**Topic:** Professional Identity & Patient Resistance...\n",
      "\n",
      "2. Coping with Resistance (Spinal Cord Injury)\n",
      "   ID: scenario-10\n",
      "   Score: 0.4894\n",
      "   Preview: # Scenario 10: Coping with Resistance (Spinal Cord Injury)\n",
      "**Topic:** Rehabilitation & Emotional Res...\n",
      "\n",
      "âœ… Retrieval test successful!\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ§ª Testing retrieval with sample query...\\n\")\n",
    "\n",
    "test_query = '''\n",
    "×× ×™ ××¨×¤××” ×‘×¢×™×¡×•×§ ××ª×—×™×œ×”, ×¡×™×™××ª×™ ××ª ×œ×™××•×“×™×™ ×œ×¤× ×™ ×›×—×¦×™ ×©× ×” ×•×”×™×•× ×× ×™ ×¤×•×’×©×ª ××ª ×”××˜×•×¤×œ ×”×¨××©×•×Ÿ ×©×œ×™. ×”××˜×•×¤×œ ×©×œ×™ ×”×•× ×‘×Ÿ 56, ×”×•× ×’×‘×¨ ×¢×¦×××™ ×¢× ××’×• ×’×‘×¨×™. ×”×•× ×¢×•×‘×“ ×‘×›×™×¨ ×‘×¢×™×¨×™×™×” ×©××›×™×¨ ××ª ×›×•×œ× ×•×›×•×œ× ××›×™×¨×™× ××•×ª×•. ×”×•× ×¨×’×™×œ ×œ×”×™×•×ª ×¢×¦×××™ ×ª××™×“ ×•×—×©×•×‘ ×œ×• × ×•×¨× ×”×›×‘×•×“ ×”×¢×¦××™ ×©×œ×•. ×”×•× ×¢×‘×¨ ×ª××•× ×ª ×“×¨×›×™× ×§×©×” ×•×‘×¢×§×‘×•×ª ×–×” ×”×•× ××ª× ×™×™×“ ×‘×›×™×¡× ×’×œ×’×œ×™×. ×”×•× × ×¤×¦×¢ ×§×©×” ×‘×¨×’×œ×™×• ×•×”×•× ×¦×¨×™×š ×œ×œ××•×“ ××—×“×© ××™×š ×œ×œ×›×ª. ×ª×™×™×¢×¥ ×œ×™ ×‘×‘×§×©×” ×¢×œ ×¨×¢×™×•× ×•×ª ×©×œ ××™×š ×œ×”×ª×—×™×œ ××ª ×”××¤×’×© ×”×¨××©×•×Ÿ ×©×œ× ×•.\n",
    "'''\n",
    "results = vector_store.similarity_search_with_score(test_query, k=2)\n",
    "\n",
    "print(f\"Query: '{test_query}'\\n\")\n",
    "print(\"Top 2 matches:\")\n",
    "for i, (doc, score) in enumerate(results, 1):\n",
    "    print(f\"\\n{i}. {doc.metadata['title']}\")\n",
    "    print(f\"   ID: {doc.metadata['id']}\")\n",
    "    print(f\"   Score: {score:.4f}\")\n",
    "    print(f\"   Preview: {doc.page_content[:100]}...\")\n",
    "\n",
    "print(\"\\nâœ… Retrieval test successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Ingestion complete! The ChromaDB database is now ready for use by the Streamlit app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "âœ¨ INGESTION COMPLETE âœ¨\n",
      "============================================================\n",
      "\n",
      "ğŸ“Š Total scenarios ingested: 18\n",
      "ğŸ’¾ Database location: ./app/data/chroma_db\n",
      "ğŸ“¦ Collection name: ot_scenarios\n",
      "\n",
      "ğŸš€ You can now run the Streamlit app with:\n",
      "   cd ..\n",
      "   streamlit run app.py\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ¨ INGESTION COMPLETE âœ¨\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nğŸ“Š Total scenarios ingested: {len(documents)}\")\n",
    "print(f\"ğŸ’¾ Database location: {config.chroma_db_path}\")\n",
    "print(f\"ğŸ“¦ Collection name: {config.chroma_collection_name}\")\n",
    "print(\"\\nğŸš€ You can now run the Streamlit app with:\")\n",
    "print(\"   cd ..\")\n",
    "print(\"   streamlit run app.py\")\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ChromaDB contains 18 documents:\n",
      "\n",
      "         ID                                            Title         Source  Content Length\n",
      " scenario-1                  Refusal of Treatment by Student  scenario-1.md            6137\n",
      "scenario-10      Coping with Resistance (Spinal Cord Injury) scenario-10.md            6187\n",
      "scenario-11         Interprofessional Conflict in Psych Ward scenario-11.md            5975\n",
      "scenario-12    Ethical Dilemma & Involuntary Hospitalization scenario-12.md            6781\n",
      "scenario-13      Financial Ethics & Divorce in Mental Health scenario-13.md            5921\n",
      "scenario-14      Cultural Competence and Parental Engagement scenario-14.md            7444\n",
      "scenario-15 Language Barrier & Cultural Competence (Russian) scenario-15.md            5289\n",
      "scenario-16            Conflict with Customer over Equipment scenario-16.md            3883\n",
      "scenario-17        Stroke Patient and Husband's Interference scenario-17.md            3088\n",
      "scenario-18        Stroke Patient and Husband's Interference scenario-18.md            3088\n",
      " scenario-2               Over-Identification and Boundaries  scenario-2.md            3893\n",
      " scenario-3              Intake Interview & Emotional Parent  scenario-3.md            6160\n",
      " scenario-4           Observation Skills & Passive vs Active  scenario-4.md            3507\n",
      " scenario-5                Gifts and Professional Boundaries  scenario-5.md            3990\n",
      " scenario-6          Parental Conflict regarding School Aide  scenario-6.md            5961\n",
      " scenario-7                        Privacy and Spying Spouse  scenario-7.md            5441\n",
      " scenario-8              Adolescent ADHD and Boundary Issues  scenario-8.md            5605\n",
      " scenario-9               Autism and Engaging the Disengaged  scenario-9.md            5591\n",
      "\n",
      "============================================================\n",
      "ğŸ’¡ To view full content of a specific scenario, run:\n",
      "   doc_index = 0  # Change to desired row number\n",
      "   print(all_docs['documents'][doc_index])\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Get all documents from collection\n",
    "collection = vector_store._collection\n",
    "all_docs = collection.get(include=['metadatas', 'documents'])\n",
    "\n",
    "# Create DataFrame for easy viewing\n",
    "df = pd.DataFrame({\n",
    "    'ID': [m['id'] for m in all_docs['metadatas']],\n",
    "    'Title': [m['title'] for m in all_docs['metadatas']],\n",
    "    'Source': [m['source'] for m in all_docs['metadatas']],\n",
    "    'Content Length': [len(d) for d in all_docs['documents']]\n",
    "})\n",
    "\n",
    "print(f\"ğŸ“Š ChromaDB contains {len(df)} documents:\\n\")\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# Optional: Display full content of a specific scenario\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ’¡ To view full content of a specific scenario, run:\")\n",
    "print(\"   doc_index = 0  # Change to desired row number\")\n",
    "print(\"   print(all_docs['documents'][doc_index])\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect ChromaDB Contents\n",
    "\n",
    "View all documents stored in the database as a table."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.13.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
